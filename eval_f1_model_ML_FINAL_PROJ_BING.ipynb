{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBXHKtr84syG"
      },
      "source": [
        "# ***Hrudayangam Mehta Raghuvar Arora***\n",
        "# ***ML FINAL PROJECT***\n",
        "# *BERT FINE TUNING MODEL - eval on custom inputs* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkOCB2hOYSls"
      },
      "source": [
        "## ***Step 1:*** Download Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiXMZ8DCGTAd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ceLmdhiLCc2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer,BertTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJXcZ60W9-Uj",
        "outputId": "e65c6f64-0813-4f7b-aba5-079970d9cd4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9dnu9b9YoKz"
      },
      "source": [
        "## ***Step 2:*** Load the fine tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1AlroecLHQw",
        "outputId": "5013d55b-164e-4b84-a39f-0f850b85cf55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Define the bert tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the fine-tuned modeol\n",
        "model = torch.load(\"/content/drive/MyDrive/finetunedmodel\",map_location=torch.device('cpu'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjh85hqyY-2A"
      },
      "source": [
        "## ***Step 3:*** Make the prediction and evaluate it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyWMyNM2ZFNd"
      },
      "source": [
        " useful functions from the evaluation script of SQuAD dataset 2.0 so as to evaluate fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbLzCx8FLN4K"
      },
      "outputs": [],
      "source": [
        "def predict(context,query):\n",
        "\n",
        "  inputs = tokenizer.encode_plus(query, context, return_tensors='pt')\n",
        "\n",
        "  outputs = model(**inputs)\n",
        "  answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
        "  answer_end = torch.argmax(outputs[1]) + 1 \n",
        "\n",
        "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "  return answer\n",
        "\n",
        "def normalize_text(s):\n",
        "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "  import string, re\n",
        "\n",
        "  def remove_articles(text):\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    return re.sub(regex, \" \", text)\n",
        "\n",
        "  def white_space_fix(text):\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "  pred_tokens = normalize_text(prediction).split()\n",
        "  truth_tokens = normalize_text(truth).split()\n",
        "  \n",
        "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "    return int(pred_tokens == truth_tokens)\n",
        "  \n",
        "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "  \n",
        "  # if there are no common tokens then f1 = 0\n",
        "  if len(common_tokens) == 0:\n",
        "    return 0\n",
        "  \n",
        "  prec = len(common_tokens) / len(pred_tokens)\n",
        "  rec = len(common_tokens) / len(truth_tokens)\n",
        "  \n",
        "  return 2 * (prec * rec) / (prec + rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtMtke3JbCSR"
      },
      "outputs": [],
      "source": [
        "def give_an_answer(context,query,answer):\n",
        "\n",
        "  prediction = predict(context,query)\n",
        "  em_score = compute_exact_match(prediction, answer)\n",
        "  f1_score = compute_f1(prediction, answer)\n",
        "\n",
        "  print(f\"Question: {query}\")\n",
        "  print(f\"Prediction: {prediction}\")\n",
        "  print(f\"True Answer: {answer}\")\n",
        "  print(f\"EM: {em_score}\")\n",
        "  print(f\"F1: {f1_score}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2tXL-jNbKkK"
      },
      "source": [
        "## ***Step 4:*** Test my model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIDLoiyhbP_D"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg6XNgM9b15M"
      },
      "source": [
        "#### As you can see my model predicted all the answers correct in a very small an easy example."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create a list of predicted answers and corresponding ground truth answers\n",
        "predictions = ['The cat is sleeping', 'The dog is running', 'The bird is singing']\n",
        "ground_truth = ['The cat is sleeping', 'The dog is playing', 'The bird is chirping']\n",
        "\n",
        "# calculate the F1 score for each predicted answer and corresponding ground truth answer\n",
        "f1_scores = [compute_f1(p, t) for p, t in zip(predictions, ground_truth)]\n",
        "\n",
        "# create a bar chart of F1 scores\n",
        "plt.bar(range(len(f1_scores)), f1_scores)\n",
        "plt.xticks(range(len(predictions)), predictions)\n",
        "plt.xlabel('Predicted answers')\n",
        "plt.ylabel('F1 score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Ykf5T5rwEvUn",
        "outputId": "5443aeed-7db2-49c5-d2c3-cab95ffb7db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"Hi! My name is Hruday, I study ML. I have an 'A' grade in my project. I am 21 years old.\"\n",
        "\n",
        "queries = [\"How old is Hruday?\",\n",
        "           \"What does Hruday study?\",\n",
        "           \"Where did he get an A grade?\"\n",
        "          ]\n",
        "answers = [\"21 yearsS old\",\n",
        "           \"ML\",\n",
        "           \"ML\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRsQSFIZsjuY",
        "outputId": "6f4fd82e-2860-412a-f56d-fa569bf75c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How old is Hruday?\n",
            "Prediction: 21 years old.\n",
            "True Answer: 21 yearsS old\n",
            "EM: 0\n",
            "F1: 0.6666666666666666\n",
            "\n",
            "\n",
            "Question: What does Hruday study?\n",
            "Prediction: ml.\n",
            "True Answer: ML\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n",
            "Question: Where did he get an A grade?\n",
            "Prediction: ml.\n",
            "True Answer: ML\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smJvu24DPWxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd8050c-2f81-4189-9d2f-4c45d96d26e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How old is Alexa?\n",
            "Prediction: 21\n",
            "True Answer: 21\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n",
            "Question: Where does Alexa live now?\n",
            "Prediction: peristeri\n",
            "True Answer: Kaisariani of Athens\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: Where Alexa used to live?\n",
            "Prediction: peristeri\n",
            "True Answer: Peristeri of Athens\n",
            "EM: 0\n",
            "F1: 0.5\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"Hi! My name is Alexa and I am 21 years old. I used to live in Peristeri of Athens, but now I moved on in Kaisariani of Athens.\"\n",
        "\n",
        "queries = [\"How old is Alexa?\",\n",
        "           \"Where does Alexa live now?\",\n",
        "           \"Where Alexa used to live?\"\n",
        "          ]\n",
        "answers = [\"21\",\n",
        "           \"Kaisariani of Athens\",\n",
        "           \"Peristeri of Athens\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q03Pn8BgcCY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SsSHQMqU2oy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ac1ed1-9545-4957-a824-921206388009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: When did Queen found?\n",
            "Prediction: 1970.\n",
            "True Answer: 1970\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n",
            "Question: Who were the basic members of Queen band?\n",
            "Prediction: progressive rock, hard rock and heavy metal,\n",
            "True Answer: Freddie Mercury, Brian May, Roger Taylor and John Deacon\n",
            "EM: 0\n",
            "F1: 0.125\n",
            "\n",
            "\n",
            "Question: What kind of band they are?\n",
            "Prediction: \n",
            "True Answer: rock\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\" Queen are a British rock band formed in London in 1970. Their classic line-up was Freddie Mercury (lead vocals, piano), \n",
        "            Brian May (guitar, vocals), Roger Taylor (drums, vocals) and John Deacon (bass). Their earliest works were influenced \n",
        "            by progressive rock, hard rock and heavy metal, but the band gradually ventured into more conventional and radio-friendly \n",
        "            works by incorporating further styles, such as arena rock and pop rock. \"\"\"\n",
        "\n",
        "queries = [\"When did Queen found?\",\n",
        "           \"Who were the basic members of Queen band?\",\n",
        "           \"What kind of band they are?\"\n",
        "          ]\n",
        "answers = [\"1970\",\n",
        "           \"Freddie Mercury, Brian May, Roger Taylor and John Deacon\",\n",
        "           \"rock\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QOE-oEKjQru"
      },
      "source": [
        " with arithmetic answers and with questions that have the same words as the context, model went very well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssAaoM6jj1RQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6fc319-66de-4580-c251-946f36b1c144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many metres is Olympus?\n",
            "Prediction: 52\n",
            "True Answer: 2917\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: Where Olympus is near?\n",
            "Prediction: mount olympus is the highest mountain in greece. it is part of the olympus massif near the gulf of thermai of the aegean sea, located in the olympus range on the border between thessaly and macedonia, between the regional units of pieria and larissa, about 80 km ( 50 mi ) southwest from thessaloniki. mount olympus has 52\n",
            "True Answer: Gulf of Thérmai of the Aegean Sea\n",
            "EM: 0\n",
            "F1: 0.14545454545454545\n",
            "\n",
            "\n",
            "Question: How far away is Olympus from Thessaloniki?\n",
            "Prediction: 52\n",
            "True Answer: 80 km (50 mi)\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\" Mount Olympus is the highest mountain in Greece. It is part of the Olympus massif near \n",
        "              the Gulf of Thérmai of the Aegean Sea, located in the Olympus Range on the border between \n",
        "              Thessaly and Macedonia, between the regional units of Pieria and Larissa, about 80 km (50 mi) \n",
        "              southwest from Thessaloniki. Mount Olympus has 52 peaks and deep gorges. The highest peak, \n",
        "              Mytikas, meaning \"nose\", rises to 2917 metres (9,570 ft). It is one of the \n",
        "              highest peaks in Europe in terms of topographic prominence. \"\"\"\n",
        "\n",
        "queries = [\n",
        "           \"How many metres is Olympus?\",\n",
        "           \"Where Olympus is near?\",\n",
        "           \"How far away is Olympus from Thessaloniki?\"\n",
        "          ]\n",
        "answers = [\n",
        "           \"2917\",\n",
        "           \"Gulf of Thérmai of the Aegean Sea\",\n",
        "           \"80 km (50 mi)\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxV3qCAvj3ZS"
      },
      "source": [
        "Here I give to the model a bigger context and in particular something from COVID-19. At least here it predicted more correct answers than my two first models haha :)\n",
        "\n",
        "If I asked a question that there isn't any answer in the context or it is irrelevant, then it rightly find no answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6c16XCHoRTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61dc33ff-5964-46bf-a3fc-478fb20ae8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is COVID-19?\n",
            "Prediction: the coronavirus pandemic,\n",
            "True Answer: an ongoing pandemic of coronavirus disease 2019\n",
            "EM: 0\n",
            "F1: 0.5\n",
            "\n",
            "\n",
            "Question: What is caused by COVID-19?\n",
            "Prediction: \n",
            "True Answer: severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: How many cases have been confirmed from COVID-19?\n",
            "Prediction: 2019\n",
            "True Answer: more than 105 million cases\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: How many deaths have been confirmed from COVID-19?\n",
            "Prediction: 2019\n",
            "True Answer: more than 2.3 million deaths\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: How is COVID-19 spread?\n",
            "Prediction: \n",
            "True Answer: mainly through the air when people are near each other. It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. It may also spread via contaminated surfaces.\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: How long can an infected person remain infected?\n",
            "Prediction: two weeks,\n",
            "True Answer: up to two weeks\n",
            "EM: 0\n",
            "F1: 0.6666666666666666\n",
            "\n",
            "\n",
            "Question: Can a infected person spread the virus even if they don't have symptoms?\n",
            "Prediction: covid - 19 pandemic, also known as the coronavirus pandemic, is an ongoing pandemic of coronavirus disease 2019\n",
            "True Answer: yes\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: What do elephants eat?\n",
            "Prediction: \n",
            "True Answer: \n",
            "EM: 1\n",
            "F1: 1\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\" The COVID-19 pandemic, also known as the coronavirus pandemic, is an ongoing pandemic of coronavirus disease 2019 (COVID-19) \n",
        "              caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It was first identified in December 2019 in Wuhan, China. \n",
        "              The World Health Organization declared the outbreak a Public Health Emergency of International Concern in January 2020 and a pandemic \n",
        "              in March 2020. As of 6 February 2021, more than 105 million cases have been confirmed, with more than 2.3 million deaths attributed to COVID-19.\n",
        "              Symptoms of COVID-19 are highly variable, ranging from none to severe illness. The virus spreads mainly through the air when people are \n",
        "              near each other.[b] It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. \n",
        "              It may also spread via contaminated surfaces. People remain infectious for up to two weeks, and can spread the virus even if they do not show symptoms.[9]\"\"\"\n",
        "\n",
        "queries = [\n",
        "           \"What is COVID-19?\",\n",
        "           \"What is caused by COVID-19?\",\n",
        "           \"How many cases have been confirmed from COVID-19?\",\n",
        "           \"How many deaths have been confirmed from COVID-19?\",\n",
        "           \"How is COVID-19 spread?\",\n",
        "           \"How long can an infected person remain infected?\",\n",
        "           \"Can a infected person spread the virus even if they don't have symptoms?\",\n",
        "           \"What do elephants eat?\"\n",
        "          ]\n",
        "answers = [\n",
        "           \"an ongoing pandemic of coronavirus disease 2019\",\n",
        "           \"severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\",\n",
        "           \"more than 105 million cases\",\n",
        "           \"more than 2.3 million deaths\",\n",
        "           \"mainly through the air when people are near each other. It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. It may also spread via contaminated surfaces.\",\n",
        "           \"up to two weeks\",\n",
        "           \"yes\",\n",
        "           \"\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# true labels of the dataset - selected at random \n",
        "true_labels = [0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
        "\n",
        "# predicted labels from the BERT base uncased model - of those random test \n",
        "predicted_labels = [1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
        "\n",
        "# calculate the F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# print the F1 score\n",
        "print(f\"The F1 score of the BERT base uncased model is: {f1}\")\n"
      ],
      "metadata": {
        "id": "ZrImEBvDLrwO",
        "outputId": "49d94680-b06f-4942-f2ba-a3788ce2a2ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The F1 score of the BERT base uncased model is: 0.6666666666666665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt2uOfwDllpE"
      },
      "source": [
        " Harry Potter Wikipedia informations and more difficult questions like \"Who is the enemy of Harry Potter?\" that didn't find any answer because it doesn't explicitly refer to him as an enemy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc7p-e4wj47T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64930e5-9e7e-474e-a4d6-13f1d78d9406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who wrote Harry Potter's novels?\n",
            "Prediction: \n",
            "True Answer: J. K. Rowling\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: Who are Harry Potter's friends?\n",
            "Prediction: \n",
            "True Answer: Hermione Granger and Ron Weasley\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: Who is the enemy of Harry Potter?\n",
            "Prediction: \n",
            "True Answer: Lord Voldemort\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: What are Muggles?\n",
            "Prediction: \n",
            "True Answer: non-magical people\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: Which is the name of Harry Poter's first novel?\n",
            "Prediction: \n",
            "True Answer: Harry Potter and the Philosopher's Stone\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: When did the first novel release?\n",
            "Prediction: 1997,\n",
            "True Answer: 26 June 1997\n",
            "EM: 0\n",
            "F1: 0.5\n",
            "\n",
            "\n",
            "Question: Who was attracted by Harry Potter novels?\n",
            "Prediction: \n",
            "True Answer: a wide adult audience as well as younger readers\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: How many languages Harry Potter has been translated into? \n",
            "Prediction: \n",
            "True Answer: eighty\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\" Harry Potter is a series of seven fantasy novels written by British author, J. K. Rowling. The novels chronicle the lives of a young wizard, \n",
        "              Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and Wizardry. \n",
        "              The main story arc concerns Harry's struggle against Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard \n",
        "              governing body known as the Ministry of Magic and subjugate all wizards and Muggles (non-magical people). Since the release of the first novel, \n",
        "              Harry Potter and the Philosopher's Stone, on 26 June 1997, the books have found immense popularity, positive reviews, and commercial success worldwide. \n",
        "              They have attracted a wide adult audience as well as younger readers and are often considered cornerstones of modern young adult literature.[2] \n",
        "              As of February 2018, the books have sold more than 500 million copies worldwide, making them the best-selling book series in history, and have been translated \n",
        "              into eighty languages.[3] The last four books consecutively set records as the fastest-selling books in history, with the final installment selling roughly \n",
        "              eleven million copies in the United States within twenty-four hours of its release.  \"\"\"\n",
        "\n",
        "queries = [\n",
        "           \"Who wrote Harry Potter's novels?\",\n",
        "           \"Who are Harry Potter's friends?\",\n",
        "           \"Who is the enemy of Harry Potter?\",\n",
        "           \"What are Muggles?\",\n",
        "           \"Which is the name of Harry Poter's first novel?\",\n",
        "           \"When did the first novel release?\",\n",
        "           \"Who was attracted by Harry Potter novels?\",\n",
        "           \"How many languages Harry Potter has been translated into? \"\n",
        "          ]\n",
        "answers = [\n",
        "           \"J. K. Rowling\",\n",
        "           \"Hermione Granger and Ron Weasley\",\n",
        "           \"Lord Voldemort\",\n",
        "           \"non-magical people\",\n",
        "           \"Harry Potter and the Philosopher's Stone\",\n",
        "           \"26 June 1997\",\n",
        "           \"a wide adult audience as well as younger readers\",\n",
        "           \"eighty\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}